{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8794dc7-6612-430b-a50b-7b2ef71b1520",
   "metadata": {},
   "source": [
    "# Guam PDN Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5794902-8268-4826-a2a9-807941409889",
   "metadata": {},
   "source": [
    "## About This Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc5e664-094f-4ac7-b04d-a2e5d3d67b04",
   "metadata": {},
   "source": [
    "This notebook contains a script to scrape and extract the news articles written by Peter Onedera in the Chamorro language, which are found on the Guam Pacific Daily News website. The goal is to make the Chamorro text and its English translations accessible for future analysis, research, corpus development, lexicon expansion, and general language learning support. The text will be collected and processed in the following ways:\n",
    "\n",
    "1. Exported to an HTML file for conversion to reader-friendly formats, such as PDF or EPUB\n",
    "2. Split into sentences for corpus development\n",
    "3. Split into words for lexicon expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4e3bb6-37ae-4690-9323-450e33c3f4c5",
   "metadata": {},
   "source": [
    "**Name:** Schyuler Lujan <br>\n",
    "**Date Started:** 12-May-2025 <br>\n",
    "**Date Completed:** In Progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b68ad1-4daf-4b7b-97e8-8c26257645ae",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6c505d88-f566-4343-9f58-212d1a0d6c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for web scraping\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Import libraries for exporting data\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Import libraries for text cleanup and tokenization\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176a23cf-acec-4c8f-8593-d238250805e1",
   "metadata": {},
   "source": [
    "# Get URLs to Individual News Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39af4717-1166-4e4f-a654-6a2639a9dd1c",
   "metadata": {},
   "source": [
    "In this section, we will navigate to the search results on the `https://www.guampdn.com/` website for all articles that return the string `Peter R. Onedera`, scrape the search results page for links to individual news articles and return a list of the URLS for those articles. This list will be used in the following section to scrape the news article contents.\n",
    "\n",
    "The search results return 95 total articles. Each search result is wrapped in a `<h3 class=\"tnt-headline \">` tag, and the actual URL is found in anchor tags `<a href=...>`. A full example of this is as follows:\n",
    "\n",
    "`<a href=\"/news/guam-nikkei-association-to-host-panel-discussion-on-a-borrowed-land-on-saturday/article_b0be5d9a-7de1-4614-b5ca-927b8c0eb010.html\" class=\"tnt-asset-link\" aria-label=\"Guam Nikkei Association to host panel discussion on 'A Borrowed Land' on Saturday\">Guam Nikkei Association to host panel discussion on 'A Borrowed Land' on Saturday</a></h3>`\n",
    "\n",
    "Additionally, the URL is only a partial URL, so we will need to append the string `https://www.guampdn.com` to each scraped URL to get the full URL that allows us to navigate to each page individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e6ebd24-f22d-4e2a-aaf4-5080d8e930bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the URL for the search results we want to scrape\n",
    "search_results_url = 'https://www.guampdn.com/search/?tncms_csrf_token=8aa59fd64255a8027984365cf4d5940225badd3ae071725448f722b34652fe4f.cfd1ce29e6d3196090bc&f=html&t=article&s=start_time&sd=desc&l=100&nsa=eedition&q=Peter+R.+Onedera'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943caebd-82fa-43fb-bd5f-84742cd7da48",
   "metadata": {},
   "source": [
    "## Detect Content Written in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9fd0ac33-f30e-4aea-8c8c-ad37bd1b892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO write a function for detecting English-language titles, which will be used to exclude English content\n",
    "def detect_english():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a79d6f-b4e8-47ab-839f-0996d86cac4e",
   "metadata": {},
   "source": [
    "## Scrape News Article URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "af20bd72-e4fa-48ca-b737-1ebfda5cdbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(search_url):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Initialize list to store article urls\n",
    "    article_urls = []\n",
    "\n",
    "    # Set the string for appending a complete url\n",
    "    url_head = \"https://www.guampdn.com\"\n",
    "\n",
    "    # Set headers to avoid 406 error\n",
    "    headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "                  'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                  'Chrome/114.0.0.0 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'\n",
    "    }\n",
    "\n",
    "    # Navigate to the url and use BeautifulSoup to get the urls and titles for each search result\n",
    "    response = requests.get(search_url, headers=headers, timeout=10)\n",
    "    response.raise_for_status()\n",
    "    response.encoding = response.apparent_encoding\n",
    "\n",
    "    # Parse the html\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find urls for each article\n",
    "    urls = soup.find_all(\"h3\", class_=\"tnt-headline\")\n",
    "\n",
    "    # Extract the urls for each article\n",
    "    for url in urls:\n",
    "        u = url.find(\"a\")\n",
    "        article_urls.append(url_head+u[\"href\"])\n",
    "    \n",
    "    return list(set(article_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e9cb01b3-dd86-4162-873c-30c1dfdc6c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get individual news article URLS from the search results\n",
    "news_article_urls = get_urls(search_results_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "74433a0c-28f6-43a8-8664-a78c74378868",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "print(len(news_article_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b32fe80-ee48-4974-96dc-e0b2a4431e08",
   "metadata": {},
   "source": [
    "### Export News Article URLs to .CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fda33875-6f74-4093-9cce-1686e11d92da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert list to dataframe\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_article_urls \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(news_article_urls, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Safe dataframe to .csv\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df_article_urls\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murls_guam_pdn.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert list to dataframe\n",
    "df_article_urls = pd.DataFrame(news_article_urls, columns=[\"url\"])\n",
    "\n",
    "# Safe dataframe to .csv\n",
    "df_article_urls.to_csv('urls_guam_pdn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad855ee-4720-4dbe-ac98-d7043ef3e250",
   "metadata": {},
   "source": [
    "# Scrape News Article Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6071b4d-36e0-4e3e-b55c-e7962019d9db",
   "metadata": {},
   "source": [
    "In this section, we will take the list of URLS returned in the previous section, navigate to each URL, and scrape and process the news article contents. \n",
    "\n",
    "Each article follows a predictible structure: The Chamorro text is written first, the English translation. The English translation is always preceeded by the heading \"English translation.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4826785-8794-4284-a7f9-f8470ce6051f",
   "metadata": {},
   "source": [
    "The structure of the article webpages was examined to determine the elements we will extract data from. These elements are as follows:\n",
    "\n",
    "* **Chamorro Title:** `<h1 itemprop=\"headline\" class=\"headline\">`\n",
    "* **Author:** `<span itemprop=\"author\" class=\"tnt-byline\">`\n",
    "* **Date:** `<time datetime=\"2019-03-20T11:58:12+10:00\" class=\"tnt-date asset-date text-muted\">`\n",
    "* **Chamorro Text:** `<div id=\"article-body\" itemprop=\"articleBody\" class=\"asset-content  subscriber-premium\" false=\"\">` (text is wrapped in `<p>` tags)\n",
    "* **English Title:** `<h2 class=\"presto-h2\"><span class=\"exclude-from-newsgate\">`\n",
    "* **English Text:** `<p><span class=\"exclude-from-newsgate\">`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364d88fc-8bed-45ba-ad0f-297442244695",
   "metadata": {},
   "source": [
    "## Scrape News Article Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4a6832d-c9ff-4fe3-86b2-aac2360c2e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO write a function for navigating to each article URL and scraping the content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d13ac6-1564-4315-8e6a-f4dc9e4d628f",
   "metadata": {},
   "source": [
    "### Export News Article Contents to .JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15cd3807-21e0-4e2f-9c0d-2a775df7eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO export news articles to JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d8d765-5cf1-4602-94e0-cfab9f9a5e1b",
   "metadata": {},
   "source": [
    "# Format and Export Scraped News Articles to HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67deb688-89dc-4fc8-977a-636d3b988fe3",
   "metadata": {},
   "source": [
    "To-Do: Write the about for this section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1804041-33c9-4137-8dd5-2b5cebcf2c27",
   "metadata": {},
   "source": [
    "## Format Article Contents Into HTML String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa842bc8-fc80-42de-94a4-1b2fe48e333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO write a function for wrapping the news articles into an HTML formatted string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11452485-a96f-4b9b-83da-1baab65748cd",
   "metadata": {},
   "source": [
    "### Export String to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8bc2886-8502-4f87-a7e9-a39fd4ce0cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO export HTML formatted string to HTML file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63adf1cc-b76d-45a1-8293-0c756b4e3537",
   "metadata": {},
   "source": [
    "# Split Text Into Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cede7fa0-369f-4ff8-a39f-d5e857fb9530",
   "metadata": {},
   "source": [
    "## Split Article Text Into Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53d75779-4961-4418-ab4c-ea12179e5b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO write a function for splitting the article text into sentences\n",
    "# Format should be a list of tuples (Chamorro, English, Article Title, Article Author, Article Date, Article URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a08e96-9961-4c17-b3c1-4a917fe7282b",
   "metadata": {},
   "source": [
    "### Export Sentences to .CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "858fecbc-6e3f-4eb5-80bb-b280b4ae2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO export sentences to a .CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6160543e-0cc5-447e-87e3-fb8418e81392",
   "metadata": {},
   "source": [
    "# Split Text Into Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceedcf78-1b79-407c-a4e9-12524e8cbd62",
   "metadata": {},
   "source": [
    "## Split Article Text Into Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "533450dc-393d-41ce-b7df-7ac8bde0c311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO write a function for splitting article text into words, and return a list of unique words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac5521a-9f50-4367-9f9d-005b4ba8cc35",
   "metadata": {},
   "source": [
    "### Export Words to .CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4a7a6ad-3e9e-484a-b215-4016a3d22878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO export word list to a .CSV file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
